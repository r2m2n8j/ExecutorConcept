# Map Interface

- In Java, the Map interface is part of the Java Collections Framework and represents a data structure that stores data in key-value pairs. **Each key** in a **Map must** be **unique**, and it maps to a corresponding value.
- While keys must be unique, multiple keys can map to the same value.

- **Unique Keys**: No two keys in a Map can be identical. If you attempt to add an entry with an existing key, the old value associated with that key will be replaced by the new value.
- **No Direct Extension of Collection Interface**: Unlike List, Queue and Set, Map does not extend the Collection interface. It's a distinct part of the Collections Framework.

- Common Implementations:
- Several classes implement the Map interface, each offering different performance characteristics and ordering guarantees:
    - HashMap: Provides fast, constant-time performance for basic operations but does not guarantee any specific order of elements.
    - TreeMap: Stores elements in a sorted order based on the natural ordering of the keys or a custom Comparator.
    - LinkedHashMap: Maintains the insertion order of elements.
    - ConcurrentHashMap: A thread-safe alternative for concurrent environments.
- **Common Map Methods**:
    - put(K key, V value): Inserts or updates a key-value pair.
    - get(Object key): Retrieves the value associated with the specified key.
    - remove(Object key): Removes the entry associated with the specified key.
    - containsKey(Object key): Checks if the map contains the specified key.
    - keySet(): Returns a Set view of the keys contained in the map.
    - values(): Returns a Collection view of the values contained in the map.
    - entrySet(): Returns a Set view of the key-value mappings contained in the map.

- The time complexity for the map operations **put, get, remove, containsKey, keySet, values, and entrySet** is generally **O(1)** (constant time)


# What are HashMap?
- HashMap class is a component of the Java **Collections Framework** and resides within the **java.util package**. 
- It serves as the standard implementation of the **Map interface**. 
- A HashMap organizes data in the form of **key and a value pair** where each key is mapped to it’s corresponding value. 
- Each pair consists of one object acting as a key and another object serving as its value. 
- When attempting to insert a duplicate key into a HashMap, the existing value mapped with that **key is overwritten**. 
- HashMap assigns a unique identifier to any object after applying a specific formula, offering an average **time complexity of O(1)** for both **insertion and retrieval** operations.


## How HashMap works internally?
HashMap uses a **HashTable** implementation internally, which is the part of two important data structures: **LinkedList and Array**. 
It’s organized into an array of buckets, where each element represents a separate node. 
Within the Linked List, the Inner Node class includes attributes such as a **hash value, key, value, and a reference to the next node**.

- HashMap

        Buckets                         Node
        Hash code00000  ->          HashCode = B1
                                    Key = key1
                                    Value = Anuj
                                    Next = null
        
        Hash code11111  ->          HashCode = B2
                                    Key = key2
                                    Value = Anuj2
                                    Next = null

            Hash Code is a unique value That generated by HashMap class

1. Bucket 
   - HashMap initially initializes 16 buckets from 0 to 15 in heap memory, each of which references a Singly Linked List containing the entries (nodes). 
   - A HashMap comprises an array of “buckets,” each capable of accommodating one or multiple key-value pairs.

2. Load Factor and Rehashing:
   - The load factor specifies how full the HashMap can become before it automatically increases its capacity and rehashes its contents. 
   - The default load factor is **75% of the capacity**. The threshold of a HashMap is approximately the product of current capacity and load factor. 
   - As the number of elements exceeds the load factor times the current capacity, the HashMap capacity will typically be doubled and will be rehashed. 
   - Rehashing is the process of re-calculating the hash code of already stored entries. And this is the reason **why the order of elements in a HashMap in Java is not consistent**.

     - When initializing a HashMap instance in Java, you have the choice to set both an initial capacity and a load factor. 
         - Here’s how you can set the load factor during HashMap creation:

                Map<KeyType, ValueType> hashMap = new HashMap<>(16, 0.75f);

3. Hashing:
   - When you add a key-value pair to the HashMap using the **put method**, the **HashMap class** computes the **hash code of the key**. It then uses this hash code to determine the **index of the bucket** where the **key-value pair should be stored in the array**. 
   - **Hashing** is a technique of generating the hashcode of the object. To achieve this **hashCode() method** is used. 
   - hashCode() method of the **object class returns the memory reference of an object in integer form**. 
   - This hash code determines the index within an array called the bucket, where the value will be stored.

        - **_Note_**: We can override hashCode() function and give your own implementation.

4. Collision:
   - A collision occurs when two or more keys hash to the same index (position) within the underlying array, but the keys are not equal.
   - A case where two keys are different but the hash code is same then this is called collision.
     - HashMaps handle **collisions** by using a technique called **chaining**, where multiple key-value pairs with the same hash code are stored in a **linked list within the same bucket**. 
     - When _**retrieving a value**_ associated with a key, the HashMap iterates through the linked list (if present) in the corresponding bucket to find the correct key-value pair.

5. equals():
   - When hash **collision occurs** the **equals() method** is used to check if the element present at that position is equal, if equal it will simply override the value to the new value, if not **it results into collisions**.
   - HashMaps in Java do not allow duplicate keys because they are designed to store key-value pairs, where each key must be unique. This uniqueness ensures that each key is associated with only one value, **facilitating efficient retrieval of values based on keys**.

      - **_Note_**: The order of elements in a HashMap in Java is not guaranteed to be consistent across different iterations or operations. This is because the **internal implementation** of HashMap **does not preserve the insertion order of elements**. While the elements are stored in the HashMap based on their hash codes and bucket indices, the order in which they are stored may change due to factors such as **resizing or rehashing**.




## Changes in Java 8 implementation
- Retrieval during collisions was slower before Java 8 because, in earlier versions, HashMaps used a **linked list to handle collisions**. When multiple keys hashed to the same index (bucket), their key-value pairs were stored in a linked list within that bucket.

- **During retrieval**, the HashMap had to **iterate through the entire linked list** within the bucket to find the **key-value pair corresponding to the desired key**.
- This linear search process had a **time complexity of O(n)**, where n is the number of elements in the linked list. 
- As the number of collisions increased, the length of the **linked lists grew**, **leading to slower retrieval times**.

- Hence to solve this problem **Tree data structure is used instead of Linked list to handle collisions**.

- In Java 8, when the number of nodes in a **single bucket reaches a threshold** called **Treeify Threshold** the HashMap converts the internal structure of that bucket from a **linked list to a Tree data structure**. 
- All node within the bucket are converted into TreeNode. 
- The HashMap converts the linked list to a balanced tree during rehashing process reducing the time taken for retrieval process from **O(n) to O(log(n))**.

    - **_Note_** if the nodes in the bucket **reduces to a certain threshold** the **tree is converted back to linked list**. 
    - This helps **efficient use of memory and balance the performance** as **Tree takes more memory**.













